# * small noise level stage (fewer number of noise levels will be considered during this diffusion process) *
# * while the noise magnitude of each noise level is also determined by sigma_begin and sigma_end *
# under current setting, as sigma_begin and sigma_end are the same (1.0e-4), leading to the beta value for each noise level (5 in total) is the same (in stage 1, it varies in different levels)
# thus, the cumprod alpha is very large, representing there is few noise added during the second stage
output_dir: pretrained_cgmodels

# print(noise_level, self.alphas, self.alphas.shape[0])
# in stage1: tensor([41, 97, 91, 72]), tensor([0.9988, 0.9975, ..., 0.0063, 0.0057, 0.0051]), 100
# in stage2 (batch_size=4): tensor([1, 2, 1, 2]), tensor([0.9999, 0.9998, 0.9997, 0.9996, 0.9995]), 5
# 实际上，对于预训练的两个阶段，对于第二个阶段的序列噪声添加，其实使用的噪声强度/方式和第一阶段是一样的，只是第二阶段由于噪声间隔设置的较少，所以序列mask只有相对较少的几种选择（但强度范围和阶段一应该是基本一致的）
# 对于结构噪声添加，是主要基于两个阶段计算出的cumprod alpha值，由于第二阶段该值很小（如上），所以第二阶段对蛋白质构象添加的噪声影响很小，符合原论文描述（但序列噪声的强度范围仍和第一阶段保持一致，只是可选范围变少）

dataset:
  class: _3did

  # path for storing original data files
  path: /3did/3did_data_large_strict/

  # path for storing the processed output storage pickle file
  output_path: /3did/

  # the name of the output pickle file (for creation and re-read)
  pickle_name: m3_3did_large_strict.pkl.gz

 # * these hyperparameters will not change during phases 1 and 2 *
  transform:
    class: Compose
    # Compose a list of transforms into one, take a series of transforms to process Protein class sequentially during batch Dataloader
    # relevant original data is provided in ./transforms/transform
    transforms:
      # - class: ProteinView # for changing the protein attribute 'view' for activating certain view-related functions (view: atom/residue)
        # view: residue
      - class: TruncateProtein # truncate proteins based on AA sequence
        max_length: 150 # 150 for residue-level
        random: True
      - class: NoiseTransform # the function to create conformers for the siamese diffusion scheme
        # noise_type: torsion # because in CG scale, it is not realistic to create conformers by rotating torsion angles, it is more suitable to implement by adding coordinate noise
        noise_type: gaussian
        # sigma: 0.1 # sigma = 0.1 and noise_type = 'torsion' are for atom-level model
        sigma: 0.3
      # - class: AtomFeature # for generating features for atom-level models (one-hot atomic type + one-hot residue type for each atom node)
        # atom_feature: residue_symbol
        # keys: ["graph", "graph2"]

task: # smaller values compared with the pretraining phase 1
  class: CGDiff
  num_mlp_layer: 3

  sigma_begin: 1.0e-4 # 1: 1.0e-3, 2: 1.0e-4
  sigma_end: 1.0e-4 # 1: 0.1, 2: 1.0e-4
  num_noise_level: 5 # 1: 100, less num_noise_level from -6~6, 2: 5
  gamma: 0.2 # 1: 0.5, 2: 0.2, less ratio for the structural loss
  use_MI: False # default: False

  # extra hyperparameter:
  seq_bb_retain: True # whether also to retain all backbone beads in forward sequence diffusion (rather than only retaining all beads in unmasked residues)
  bb4aa_feats_mask: False # when seq_bb_retain = True, considering whether BB type features of remained BB nodes of masked AAs will be closed
  angle_enhance: True # whether to use the angle information provided in itp file as auxiliary bead node features

  model: # same to the model structure in phase 1
    class: CG22_GearNetIEConv
    input_dim: 31 # bead type number (23) + 4*2 angle features (angle_enhance=True)
    # input_dim: 23 # bead type number
    hidden_dims: [256, 256, 256, 256, 256, 256]
    batch_norm: True
    concat_hidden: True
    short_cut: True
    readout: sum
    # num_relation: 1 # original relation number (only containing radius edges)
    num_relation: 7 # across_res_mask: +1, cg_edge_enhance: +5

    edge_input_dim: 65 # cg3_gearnet: 58 + num_relation
    # edge_input_dim: 59 # gearnet: 52 + num_relation
    num_angle_bin: 8
    # extra hyperparameter for GearNetIEConv-based models:
    embedding_dim: 256 # extra linear embedding layer
    # layer_norm: True
    # dropout: 0.2
    # use_ieconv: True

  graph_construction_model:
    class: CG3_GraphConstruction
    edge_layers:
      # - class: SpatialEdge
        # radius: 4.5
        # min_distance: 0
      - class: AdvSpatialEdge
        radius: 5 # empirically, MARTINI-based edge cutoff can also be tried starting from 4A~5A
        min_distance: 0
        across_res_mask: True # distinguish whether bead nodes are across two residues or not
        cg_edge_enhance: True # enhance the radius edge with CG defined edges
        cg_edge_reduction: False # whether to remove the duplicate CG edges on the top of the radius edges
    edge_feature: cg3_gearnet # input attribute of initialization function of CG3_GraphConstruction
    # edge_feature: gearnet

optimizer:
  class: Adam
  lr: 1.0e-4

engine: 
  gpus: [0]
  batch_size: 64 # default: 64
  log_interval: 100 # default: 100

save_interval: 5 # save model every 'save_interval' epoch
save_model: True # only save the encoder

# set to None: no pre-trained model will be loaded
# model_checkpoint: None
# model_checkpoint: {{ ckpt }}
# model_check_point: martini3_cgdiff_seed0_gamma0.5_bs64_epoch200_dim256_length150_radius5_extra_cg3_step1_0_ls3did_bbfeatsFalse_miFalse.pth
model_check_point: martini3_cgdiff_seed0_gamma0.5_bs64_epoch200_dim256_length150_radius5_extra_cg3_step1_1_ls3did_bbfeatsFalse_miFalse.pth

train:
  num_epoch: 50 # default: 50

# extra information attached to the saved model name
extra: cg3_step2_0_ls3did_fepoch200_bbfeatsFalse_miFalse

